{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-06T16:38:46.780202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from autoencoder import DNIAnomalyDetector, DNIDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_autoencoder(model_path, test_dir, batch_size=32):\n",
    "    \"\"\"\n",
    "    Test autoencoder model on a directory of images.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the autoencoder model\n",
    "        test_dir: Directory containing test images\n",
    "        batch_size: Batch size for testing\n",
    "    \"\"\"\n",
    "    # Cargar modelo\n",
    "    detector = DNIAnomalyDetector(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    detector.load_model(model_path)\n",
    "    detector.encoder.eval()\n",
    "    detector.decoder.eval()\n",
    "\n",
    "    # Calcular errores\n",
    "    print(\"\\nCalculando errores de reconstrucción...\")\n",
    "    errors = compute_reconstruction_errors(detector, test_dir, batch_size)\n",
    "\n",
    "    # Visualizar histograma\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=50, alpha=0.75, color='blue', label=f'Images (n={len(errors)})')\n",
    "    plt.axvline(x=detector.threshold, color='red', linestyle='--', \n",
    "                label=f'Model Threshold: {detector.threshold:.6f}')\n",
    "    plt.title('Distribution of Reconstruction Errors')\n",
    "    plt.xlabel('MSE Reconstruction Error')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('reconstruction_errors.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Imprimir estadísticas\n",
    "    above_threshold = np.sum(errors > detector.threshold)\n",
    "    below_threshold = len(errors) - above_threshold\n",
    "    \n",
    "    print(\"\\nEstadísticas de errores de reconstrucción:\")\n",
    "    print(f\"Imágenes por encima del threshold: {above_threshold}/{len(errors)} ({100*above_threshold/len(errors):.2f}%)\")\n",
    "    print(f\"Imágenes por debajo del threshold: {below_threshold}/{len(errors)} ({100*below_threshold/len(errors):.2f}%)\")\n",
    "    print(f\"\\nMedia: {errors.mean():.6f}\")\n",
    "    print(f\"Mediana: {np.median(errors):.6f}\")\n",
    "    print(f\"Desviación estándar: {errors.std():.6f}\")\n",
    "    print(f\"Mínimo: {errors.min():.6f}\")\n",
    "    print(f\"Máximo: {errors.max():.6f}\")\n",
    "\n",
    "def compute_reconstruction_errors(detector, data_dir, batch_size=32):\n",
    "    \"\"\"Calcular errores de reconstrucción para todas las imágenes.\"\"\"\n",
    "    dataset = DNIDataset(data_dir, detector.transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    errors = []\n",
    "    first_batch = True\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Procesando imágenes\"):\n",
    "            imgs = batch.to(detector.device)\n",
    "            \n",
    "            if first_batch:\n",
    "                # Imprimir dimensiones de debug\n",
    "                x = detector.encoder.conv(imgs)\n",
    "                flattened = x.view(x.size(0), -1)\n",
    "                print(f\"\\nDimensiones:\")\n",
    "                print(f\"Input images: {imgs.shape}\")\n",
    "                print(f\"After conv layers: {x.shape}\")\n",
    "                print(f\"Flattened: {flattened.shape}\")\n",
    "                print(f\"FC layer expects input: {detector.encoder.fc.in_features}\")\n",
    "                first_batch = False\n",
    "            \n",
    "            try:\n",
    "                latent = detector.encoder(imgs)\n",
    "                reconstructed = detector.decoder(latent)\n",
    "                batch_errors = torch.nn.functional.mse_loss(\n",
    "                    reconstructed, imgs, reduction='none'\n",
    "                ).mean(dim=[1,2,3]).cpu().numpy()\n",
    "                errors.extend(batch_errors)\n",
    "            except RuntimeError as e:\n",
    "                print(\"\\nError de dimensiones detectado.\")\n",
    "                print(f\"Último tensor shape: {x.shape}\")\n",
    "                print(f\"FC layer input size: {detector.encoder.fc.in_features}\")\n",
    "                print(f\"FC layer output size: {detector.encoder.fc.out_features}\")\n",
    "                raise e\n",
    "            \n",
    "    return np.array(errors)\n",
    "\n",
    "# Uso\n",
    "test_autoencoder(\n",
    "    model_path='models/dni_anomaly_detector_without_yolo.pt',\n",
    "    test_dir='autoencoder_data/train_images_without_YOLO',\n",
    "    batch_size=32\n",
    ")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francobertoldi/Documents/DNI-classifier/autoencoder.py:299: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando errores de reconstrucción...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   2%|▏         | 1/63 [00:02<02:27,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones:\n",
      "Input images: torch.Size([32, 3, 224, 224])\n",
      "After conv layers: torch.Size([32, 128, 28, 28])\n",
      "Flattened: torch.Size([32, 100352])\n",
      "FC layer expects input: 100352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:  65%|██████▌   | 41/63 [01:25<00:44,  2.03s/it]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
