{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "7c1f2942b2813a97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T19:26:41.853765Z",
     "start_time": "2024-12-05T19:26:29.666787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "from autoencoder import DNIAnomalyDetector\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def crop_image(image, bbox):\n",
    "    \"\"\"Crop image using bounding box coordinates.\"\"\"\n",
    "    x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
    "    return image.crop((x1, y1, x2, y2))\n",
    "\n",
    "def process_image(image_path, yolo_model, detector, loss_weights):\n",
    "    \"\"\"\n",
    "    Process a single image: YOLO for cropping, then Autoencoder for validation.\n",
    "    \"\"\"\n",
    "    # Usar YOLO solo para detectar y recortar\n",
    "    results = yolo_model(image_path)[0]\n",
    "\n",
    "    # Si no hay detecciones, usar la imagen original\n",
    "    if len(results.boxes) == 0:\n",
    "        return detector.predict(image_path, loss_weights=loss_weights)\n",
    "\n",
    "    # Obtener la detección con mayor confianza para el recorte\n",
    "    confidences = results.boxes.conf.cpu().numpy()\n",
    "    best_idx = confidences.argmax()\n",
    "    box = results.boxes[best_idx]\n",
    "\n",
    "    # Recortar imagen usando el bbox\n",
    "    original_image = Image.open(image_path)\n",
    "    bbox = box.xyxy[0].cpu().numpy()\n",
    "    cropped_image = crop_image(original_image, bbox)\n",
    "\n",
    "    # Guardar temporalmente la imagen recortada\n",
    "    temp_crop_path = f\"temp_crop_{os.path.basename(image_path)}\"\n",
    "    try:\n",
    "        cropped_image.save(temp_crop_path)\n",
    "        # Validar con Autoencoder\n",
    "        return detector.predict(temp_crop_path, loss_weights=loss_weights)\n",
    "    finally:\n",
    "        if os.path.exists(temp_crop_path):\n",
    "            os.remove(temp_crop_path)\n",
    "\n",
    "def test_detector(model_path, yolo_path, test_dir, anomaly_threshold=0.5, loss_weights={'mse': 1.0, 'ssim': 0.0}):\n",
    "    \"\"\"\n",
    "    Test the DNI Anomaly Detector with YOLO preprocessing for cropping.\n",
    "    \"\"\"\n",
    "    # Initialize models\n",
    "    yolo_model = YOLO(yolo_path)\n",
    "    detector = DNIAnomalyDetector()\n",
    "    detector.load_model(model_path)\n",
    "    \n",
    "    # Print configuration\n",
    "    print(\"\\nModel Configuration:\")\n",
    "    print(f\"Autoencoder Threshold: {detector.threshold:.6f}\")\n",
    "    print(f\"Loss Weights: MSE={loss_weights['mse']}, SSIM={loss_weights['ssim']}\")\n",
    "    print(f\"Anomaly Classification Threshold: {anomaly_threshold}\")\n",
    "    \n",
    "    # Process test images\n",
    "    test_path = Path(test_dir)\n",
    "    test_images = list(test_path.glob('*.jpg'))\n",
    "    \n",
    "    results = []\n",
    "    confidences = []\n",
    "    \n",
    "    print(\"\\nTesting images...\")\n",
    "    with torch.no_grad():\n",
    "        for img_path in tqdm(test_images, desc=\"Processing images\"):\n",
    "            try:\n",
    "                confidence = process_image(str(img_path), yolo_model, detector, loss_weights)\n",
    "                confidences.append(confidence)\n",
    "                \n",
    "                results.append({\n",
    "                    'image': str(img_path),\n",
    "                    'confidence': confidence,\n",
    "                    'is_anomaly': confidence < anomaly_threshold\n",
    "                })\n",
    "                \n",
    "                print(f\"\\nImage: {img_path.name}\")\n",
    "                print(f\"Confidence: {confidence:.4f}\")\n",
    "                print(f\"Is anomaly: {confidence < anomaly_threshold}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError processing {img_path.name}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not confidences:\n",
    "        print(\"\\nNo images were processed!\")\n",
    "        return results\n",
    "    \n",
    "    # Calculate statistics\n",
    "    confidences = np.array(confidences)\n",
    "    \n",
    "    print(\"\\nConfidence Score Statistics:\")\n",
    "    print(f\"Min confidence: {confidences.min():.4f}\")\n",
    "    print(f\"Max confidence: {confidences.max():.4f}\")\n",
    "    print(f\"Mean confidence: {confidences.mean():.4f}\")\n",
    "    print(f\"Median confidence: {np.median(confidences):.4f}\")\n",
    "    print(f\"Std confidence: {confidences.std():.4f}\")\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    confidence_ranges = {\n",
    "        'Very Low (0.0-0.2)': 0,\n",
    "        'Low (0.2-0.4)': 0,\n",
    "        'Medium (0.4-0.6)': 0,\n",
    "        'High (0.6-0.8)': 0,\n",
    "        'Very High (0.8-1.0)': 0\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        conf = result['confidence']\n",
    "        if conf < 0.2:\n",
    "            confidence_ranges['Very Low (0.0-0.2)'] += 1\n",
    "        elif conf < 0.4:\n",
    "            confidence_ranges['Low (0.2-0.4)'] += 1\n",
    "        elif conf < 0.6:\n",
    "            confidence_ranges['Medium (0.4-0.6)'] += 1\n",
    "        elif conf < 0.8:\n",
    "            confidence_ranges['High (0.6-0.8)'] += 1\n",
    "        else:\n",
    "            confidence_ranges['Very High (0.8-1.0)'] += 1\n",
    "    \n",
    "    for range_name, count in confidence_ranges.items():\n",
    "        print(f\"{range_name}: {count} images ({(count/len(results))*100:.1f}%)\")\n",
    "    \n",
    "    # Print classification summary\n",
    "    anomalies = sum(1 for r in results if r['is_anomaly'])\n",
    "    print(f\"\\nClassification Summary:\")\n",
    "    print(f\"Total images tested: {len(results)}\")\n",
    "    print(f\"Anomalies detected: {anomalies} ({(anomalies/len(results))*100:.1f}%)\")\n",
    "    print(f\"Normal images: {len(results) - anomalies} ({((len(results)-anomalies)/len(results))*100:.1f}%)\")\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(confidences, bins=50, edgecolor='black')\n",
    "    plt.title('Distribution of Confidence Scores')\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.axvline(x=anomaly_threshold, color='r', linestyle='--', label=f'Anomaly Threshold ({anomaly_threshold})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('confidence_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"api/dni_anomaly_detector.pt\"\n",
    "    yolo_path = \"YOLODataset_seg/runs/segment/train2/weights/best.pt\"\n",
    "    test_dir = \"test/valid\"\n",
    "    \n",
    "    results = test_detector(\n",
    "        model_path=model_path,\n",
    "        yolo_path=yolo_path,\n",
    "        test_dir=test_dir,\n",
    "        anomaly_threshold=0.85,\n",
    "        loss_weights={'mse': 1.0, 'ssim': 0.0}\n",
    "    )"
   ],
   "id": "7310c778158233f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "Autoencoder Threshold: 0.007056\n",
      "Loss Weights: MSE=1.0, SSIM=0.0\n",
      "Anomaly Classification Threshold: 0.85\n",
      "\n",
      "Testing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e11d788-bbdd-4afa-9e12-455462d52c44.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   2%|▏         | 1/62 [00:00<00:17,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e11d788-bbdd-4afa-9e12-455462d52c44.jpg\n",
      "Confidence: 0.2882\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fa71614-d9c4-42f3-9088-7555e837d493.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   3%|▎         | 2/62 [00:00<00:15,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fa71614-d9c4-42f3-9088-7555e837d493.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00d9f307-48b7-42db-beb1-f67a3d411c0e.jpg: 640x640 1 FrenteValido, 4.4ms\n",
      "Speed: 1.2ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Image: 00d9f307-48b7-42db-beb1-f67a3d411c0e.jpg\n",
      "Confidence: 0.6677\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/Documento_Nacional_Identidad_Frente_Versión_1_df120cb0-e849-4af1-9276-2f834840593f.jpg: 384x640 1 FrenteValido, 3.3ms\n",
      "Speed: 0.6ms preprocess, 3.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Image: Documento_Nacional_Identidad_Frente_Versión_1_df120cb0-e849-4af1-9276-2f834840593f.jpg\n",
      "Confidence: 0.0471\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a7310ab-d45f-4017-95d0-57543c36e362.jpg: 544x640 1 FrenteValido, 4.5ms\n",
      "Speed: 1.1ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   8%|▊         | 5/62 [00:00<00:06,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a7310ab-d45f-4017-95d0-57543c36e362.jpg\n",
      "Confidence: 0.2932\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f14510a-904c-4f9c-821d-1f14c32fa961.jpg: 480x640 1 FrenteValido, 1 DorsoInvalido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Image: 0f14510a-904c-4f9c-821d-1f14c32fa961.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e86df5e-316b-4d41-b9c7-8fbf6072275a.jpg: 640x480 1 FrenteValido, 4.4ms\n",
      "Speed: 1.3ms preprocess, 4.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  11%|█▏        | 7/62 [00:01<00:10,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e86df5e-316b-4d41-b9c7-8fbf6072275a.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00bc40ad-8cb9-449e-b120-4ed4a5dd8aa4.jpg: 512x640 1 FrenteValido, 4.5ms\n",
      "Speed: 1.5ms preprocess, 4.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  13%|█▎        | 8/62 [00:01<00:12,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 00bc40ad-8cb9-449e-b120-4ed4a5dd8aa4.jpg\n",
      "Confidence: 0.2246\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fa96209-82c3-46fe-a952-91e193e8b772.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|█▍        | 9/62 [00:01<00:12,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fa96209-82c3-46fe-a952-91e193e8b772.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e2ea279-7536-4a20-9ad1-9127449715b0.jpg: 640x480 1 FrenteValido, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  16%|█▌        | 10/62 [00:02<00:12,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e2ea279-7536-4a20-9ad1-9127449715b0.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e91db5e-d8dd-407e-9e02-23d3b0369904.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  18%|█▊        | 11/62 [00:02<00:12,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e91db5e-d8dd-407e-9e02-23d3b0369904.jpg\n",
      "Confidence: 0.5378\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1aa7774c-4e42-4a5b-84f2-ee8cf95ae993.jpg: 640x384 1 FrenteValido, 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  19%|█▉        | 12/62 [00:02<00:10,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1aa7774c-4e42-4a5b-84f2-ee8cf95ae993.jpg\n",
      "Confidence: 0.0654\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00cce513-9faf-4f80-8a48-d4bdb7b6e996.jpg: 384x640 1 FrenteValido, 3.4ms\n",
      "Speed: 1.0ms preprocess, 3.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Image: 00cce513-9faf-4f80-8a48-d4bdb7b6e996.jpg\n",
      "Confidence: 0.0913\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a5dc3c7-20ff-4842-9fc6-9181cb0740ed.jpg: 480x640 1 FrenteValido, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  23%|██▎       | 14/62 [00:02<00:09,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a5dc3c7-20ff-4842-9fc6-9181cb0740ed.jpg\n",
      "Confidence: 0.2459\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1ae87363-ebf3-46ef-9a8f-be54e070d4cc.jpg: 320x640 1 FrenteValido, 3.2ms\n",
      "Speed: 0.9ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  24%|██▍       | 15/62 [00:03<00:08,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1ae87363-ebf3-46ef-9a8f-be54e070d4cc.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e7fb41f-80a0-4038-9c4a-8c1fa9a63e23.jpg: 640x480 1 FrenteValido, 4.9ms\n",
      "Speed: 0.8ms preprocess, 4.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "Image: 0e7fb41f-80a0-4038-9c4a-8c1fa9a63e23.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f058a4a-f433-470a-b582-1b8d1e601f0c.jpg: 640x384 1 FrenteValido, 3.3ms\n",
      "Speed: 0.6ms preprocess, 3.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "Image: 0f058a4a-f433-470a-b582-1b8d1e601f0c.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e40b8e0-62b6-4e6c-8f08-ec24f863bda1.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  29%|██▉       | 18/62 [00:03<00:06,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e40b8e0-62b6-4e6c-8f08-ec24f863bda1.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ed9eb1f-62ae-4cd9-b88e-21f1c24d37e1.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  31%|███       | 19/62 [00:03<00:07,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0ed9eb1f-62ae-4cd9-b88e-21f1c24d37e1.jpg\n",
      "Confidence: 0.3145\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a0a69b4-45f9-46a1-a9b7-dc1c4992947b.jpg: 480x640 2 FrenteValidos, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  32%|███▏      | 20/62 [00:03<00:07,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a0a69b4-45f9-46a1-a9b7-dc1c4992947b.jpg\n",
      "Confidence: 0.3991\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0efc6add-a03e-4f8b-a100-9c21caffc3d7.jpg: 480x640 1 FrenteValido, 6.0ms\n",
      "Speed: 0.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Image: 0efc6add-a03e-4f8b-a100-9c21caffc3d7.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f7f8d1e-3c5d-4aab-92f9-0e5484cc7189.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  35%|███▌      | 22/62 [00:04<00:06,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0f7f8d1e-3c5d-4aab-92f9-0e5484cc7189.jpg\n",
      "Confidence: 0.3535\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f4c37d3-0cf4-4c79-bb34-3a3c1d10fa7a.jpg: 640x640 1 FrenteValido, 4.4ms\n",
      "Speed: 1.4ms preprocess, 4.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  37%|███▋      | 23/62 [00:04<00:06,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0f4c37d3-0cf4-4c79-bb34-3a3c1d10fa7a.jpg\n",
      "Confidence: 0.2541\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0edd5d3a-be26-4817-95f2-4baef7681469.jpg: 384x640 1 FrenteValido, 3.5ms\n",
      "Speed: 1.1ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  39%|███▊      | 24/62 [00:04<00:06,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0edd5d3a-be26-4817-95f2-4baef7681469.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a6d5a86-438e-4eb7-99cd-b6dff2622685.jpg: 480x640 1 FrenteValido, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  40%|████      | 25/62 [00:04<00:07,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a6d5a86-438e-4eb7-99cd-b6dff2622685.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1af62256-41e1-4f3d-b910-6803197a3212.jpg: 448x640 1 FrenteValido, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Image: 1af62256-41e1-4f3d-b910-6803197a3212.jpg\n",
      "Confidence: 0.0098\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fa10a06-c6db-4bf6-92fd-143dcb44e368.jpg: 288x640 1 FrenteValido, 3.5ms\n",
      "Speed: 0.8ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  44%|████▎     | 27/62 [00:04<00:05,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fa10a06-c6db-4bf6-92fd-143dcb44e368.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e734b79-9cbf-4142-bb8d-33873b363cae.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  45%|████▌     | 28/62 [00:05<00:05,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e734b79-9cbf-4142-bb8d-33873b363cae.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/Documento_Nacional_Identidad_Dorso_Versión_1_1bbb1e8d-96e5-4bb9-a273-6cddba96732f.jpg: 384x640 1 FrenteValido, 1 DorsoInvalido, 1 DorsoValido, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Image: Documento_Nacional_Identidad_Dorso_Versión_1_1bbb1e8d-96e5-4bb9-a273-6cddba96732f.jpg\n",
      "Confidence: 0.0121\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e0065a8-2a8b-4444-8621-d0026d540982.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  48%|████▊     | 30/62 [00:05<00:04,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e0065a8-2a8b-4444-8621-d0026d540982.jpg\n",
      "Confidence: 0.3069\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/5d6f8c12-26ae-4a16-9db9-00a9e30b135a.jpg: 480x640 2 FrenteValidos, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  50%|█████     | 31/62 [00:05<00:04,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 5d6f8c12-26ae-4a16-9db9-00a9e30b135a.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e95895d-50d8-4479-8b8a-bb7ccd7e7784.jpg: 480x640 1 FrenteValido, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  52%|█████▏    | 32/62 [00:05<00:06,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e95895d-50d8-4479-8b8a-bb7ccd7e7784.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a446e87-f5ba-4605-a0a8-63bf29fe1824.jpg: 640x480 1 FrenteValido, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  53%|█████▎    | 33/62 [00:06<00:05,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a446e87-f5ba-4605-a0a8-63bf29fe1824.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f6859d3-28ae-48f9-a8a4-ee4e4adac273.jpg: 640x480 1 FrenteValido, 5.2ms\n",
      "Speed: 1.6ms preprocess, 5.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "Image: 0f6859d3-28ae-48f9-a8a4-ee4e4adac273.jpg\n",
      "Confidence: 0.3318\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a224e36-eb47-46a3-a29f-4b9a75cede92.jpg: 416x640 1 FrenteValido, 3.5ms\n",
      "Speed: 0.9ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  56%|█████▋    | 35/62 [00:06<00:03,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1a224e36-eb47-46a3-a29f-4b9a75cede92.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e86f913-8f3b-41da-85e6-2bc44d1c9d37.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  58%|█████▊    | 36/62 [00:06<00:03,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e86f913-8f3b-41da-85e6-2bc44d1c9d37.jpg\n",
      "Confidence: 0.0058\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ef92afc-e335-411b-90bf-a13229447764.jpg: 320x640 1 FrenteValido, 3.2ms\n",
      "Speed: 0.9ms preprocess, 3.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  60%|█████▉    | 37/62 [00:06<00:03,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0ef92afc-e335-411b-90bf-a13229447764.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1ae96584-5556-4660-83e7-a8759a464423.jpg: 320x640 1 FrenteValido, 3.1ms\n",
      "Speed: 0.8ms preprocess, 3.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  61%|██████▏   | 38/62 [00:06<00:03,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1ae96584-5556-4660-83e7-a8759a464423.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00acfec7-95a5-4646-82eb-235b092d5784.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  63%|██████▎   | 39/62 [00:06<00:04,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 00acfec7-95a5-4646-82eb-235b092d5784.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f448289-2582-4edc-935c-dcada4662309.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  65%|██████▍   | 40/62 [00:07<00:04,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0f448289-2582-4edc-935c-dcada4662309.jpg\n",
      "Confidence: 0.0598\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1a89c124-c8f6-4c47-a4ae-4ae6e9ade351.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Image: 1a89c124-c8f6-4c47-a4ae-4ae6e9ade351.jpg"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  66%|██████▌   | 41/62 [00:07<00:04,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confidence: 0.3216\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e7f70b3-9d9f-4a2d-a900-d8dba3d1305f.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  68%|██████▊   | 42/62 [00:07<00:04,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e7f70b3-9d9f-4a2d-a900-d8dba3d1305f.jpg\n",
      "Confidence: 0.1369\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e6a744a-a5f0-4052-be0f-4188cc45372f.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  69%|██████▉   | 43/62 [00:07<00:04,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e6a744a-a5f0-4052-be0f-4188cc45372f.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1aea9370-3e4d-4ad4-b91d-409ee5105f55.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  71%|███████   | 44/62 [00:08<00:04,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1aea9370-3e4d-4ad4-b91d-409ee5105f55.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1aca6d66-21b9-4e6c-a756-10a9d9257bc8.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  73%|███████▎  | 45/62 [00:08<00:03,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1aca6d66-21b9-4e6c-a756-10a9d9257bc8.jpg\n",
      "Confidence: 0.5687\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1ac8dac2-2fdf-4857-be0a-37122c8c7f13.jpg: 640x480 1 FrenteValido, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  74%|███████▍  | 46/62 [00:08<00:03,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1ac8dac2-2fdf-4857-be0a-37122c8c7f13.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00baff1c-a030-497d-ae60-7f34d0ac1971.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  76%|███████▌  | 47/62 [00:08<00:03,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 00baff1c-a030-497d-ae60-7f34d0ac1971.jpg\n",
      "Confidence: 0.0226\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ee47a8b-04dc-48cf-ac07-7087c017ef71.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  77%|███████▋  | 48/62 [00:09<00:02,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0ee47a8b-04dc-48cf-ac07-7087c017ef71.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fbbd8d7-1727-4d06-8096-6fd6f75f1ea6.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  79%|███████▉  | 49/62 [00:09<00:03,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fbbd8d7-1727-4d06-8096-6fd6f75f1ea6.jpg\n",
      "Confidence: 0.1022\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0df31401-8883-47ac-8f19-100ca6eb42f0.jpg: 640x480 1 FrenteValido, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "Image: 0df31401-8883-47ac-8f19-100ca6eb42f0.jpg\n",
      "Confidence: 0.3694\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0a1e89f6-0ae2-4cab-854e-61c897cbbe13.jpg: 480x640 1 FrenteValido, 4.3ms\n",
      "Speed: 1.2ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  82%|████████▏ | 51/62 [00:09<00:02,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0a1e89f6-0ae2-4cab-854e-61c897cbbe13.jpg\n",
      "Confidence: 0.0285\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0eeecd18-ff12-4a7d-bc9e-54eda6df54d8.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  84%|████████▍ | 52/62 [00:10<00:02,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0eeecd18-ff12-4a7d-bc9e-54eda6df54d8.jpg\n",
      "Confidence: 0.3113\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fda5871-d3ff-41b2-9f83-0bfaaa0060e1.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  85%|████████▌ | 53/62 [00:10<00:02,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fda5871-d3ff-41b2-9f83-0bfaaa0060e1.jpg\n",
      "Confidence: 0.3980\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ed9b491-3f78-4d96-bfaa-ee514b12e71e.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  87%|████████▋ | 54/62 [00:10<00:02,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0ed9b491-3f78-4d96-bfaa-ee514b12e71e.jpg\n",
      "Confidence: 0.0210\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0fbc5b96-df65-4dde-9c58-5a17ff0aea3b.jpg: 640x320 1 FrenteValido, 3.2ms\n",
      "Speed: 0.9ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  89%|████████▊ | 55/62 [00:10<00:01,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0fbc5b96-df65-4dde-9c58-5a17ff0aea3b.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/00e166c6-251d-41ee-92e9-bdeec1e24b10.jpg: 384x640 1 FrenteValido, 3.4ms\n",
      "Speed: 1.0ms preprocess, 3.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  90%|█████████ | 56/62 [00:10<00:01,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 00e166c6-251d-41ee-92e9-bdeec1e24b10.jpg\n",
      "Confidence: 0.0229\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0feed62d-0a8e-4b50-9a8b-fbda714f6734.jpg: 480x640 1 FrenteValido, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  92%|█████████▏| 57/62 [00:11<00:01,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0feed62d-0a8e-4b50-9a8b-fbda714f6734.jpg\n",
      "Confidence: 0.1219\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/1ae0b816-73e2-45bd-ad59-5f01c8a1614d.jpg: 480x640 1 FrenteValido, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  94%|█████████▎| 58/62 [00:11<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1ae0b816-73e2-45bd-ad59-5f01c8a1614d.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0f0e576d-1fc4-40cd-bd1e-1730b30bde71.jpg: 384x640 1 FrenteValido, 3.4ms\n",
      "Speed: 1.0ms preprocess, 3.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  95%|█████████▌| 59/62 [00:11<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0f0e576d-1fc4-40cd-bd1e-1730b30bde71.jpg\n",
      "Confidence: 0.2938\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ef79580-d5aa-49fb-9e60-1dc83e664001.jpg: 480x640 1 FrenteValido, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  97%|█████████▋| 60/62 [00:11<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0ef79580-d5aa-49fb-9e60-1dc83e664001.jpg\n",
      "Confidence: 0.0000\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0ec39358-8af7-462a-b677-da2ae95048fe.jpg: 416x640 1 FrenteValido, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Image: 0ec39358-8af7-462a-b677-da2ae95048fe.jpg\n",
      "Confidence: 0.2873\n",
      "Is anomaly: True\n",
      "\n",
      "image 1/1 /home/francobertoldi/Documents/DNI-classifier/test/valid/0e2ac685-526b-442d-a33f-c5e6f58e249e.jpg: 640x480 1 FrenteValido, 3.9ms\n",
      "Speed: 0.7ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 62/62 [00:11<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 0e2ac685-526b-442d-a33f-c5e6f58e249e.jpg\n",
      "Confidence: 0.1664\n",
      "Is anomaly: True\n",
      "\n",
      "Confidence Score Statistics:\n",
      "Min confidence: 0.0000\n",
      "Max confidence: 0.6677\n",
      "Mean confidence: 0.1239\n",
      "Median confidence: 0.0165\n",
      "Std confidence: 0.1702\n",
      "\n",
      "Detailed Results:\n",
      "Very Low (0.0-0.2): 43 images (69.4%)\n",
      "Low (0.2-0.4): 16 images (25.8%)\n",
      "Medium (0.4-0.6): 2 images (3.2%)\n",
      "High (0.6-0.8): 1 images (1.6%)\n",
      "Very High (0.8-1.0): 0 images (0.0%)\n",
      "\n",
      "Classification Summary:\n",
      "Total images tested: 62\n",
      "Anomalies detected: 62 (100.0%)\n",
      "Normal images: 0 (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T19:26:41.857635Z",
     "start_time": "2024-12-05T19:26:41.856406Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "834a4537fe7f58d2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
